{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental simple performance testing notebook for Spark\n",
    "- testing and comparing simple dataframe / sql operations of commong data (pre-)processing tasks \n",
    "- various available single-machine Python solutions are to be tested: Pandas, PySpark, Turi Create and Dask.\n",
    "- execution times, CPU load and maximal memory use should be tracked\n",
    "\n",
    "\n",
    "## Kiva dataset \n",
    "- [Kiva](https://www.kaggle.com/gaborfodor/additional-kiva-snapshot): crowdfunding data with lenders and loans, with additional geographic data\n",
    "- download the related CSV files and move them to a folder where the kernel can read them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split\n",
    "import timeit \n",
    "\n",
    "findspark.init()\n",
    "\n",
    "# use SparkSession instead of SparkContext:\n",
    "# setting SparkSession config paramters are necesary to use available memory (we can also limit CPUs by eg. \n",
    "# .config('spark.default.parallelism', 5), but it uses all the CPUs by default)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('PySpark local test') \\\n",
    "    .config(\"spark.core.connection.ack.wait.timeout\", \"12000\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config('spark.executor.memory', '4G') \\\n",
    "    .config('spark.driver.memory', '5G') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read files to dataframes: loans and lenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1  \n",
    "# this is a setup line for timeit (not meauserd)\n",
    "\n",
    "lenders_df = spark.read.csv(\"../../kiva/lenders.csv\", header=True)  # 130 MB file, 2.349.174 lines\n",
    "lenders_df.createOrReplaceTempView(\"lenders\") \n",
    "loans_df = spark.read.csv(\"../../kiva/loans.csv\", header=True)      # 2.1 GB file, 1.419.607 lines\n",
    "loans_df.createOrReplaceTempView(\"loans\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- permanent_name: string (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- member_since: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- loan_because: string (nullable = true)\n",
      " |-- loan_purchase_num: string (nullable = true)\n",
      " |-- invited_by: string (nullable = true)\n",
      " |-- num_invited: string (nullable = true)\n",
      "\n",
      "+--------------+------------+----+-----+------------+------------+----------+------------+-----------------+----------+-----------+\n",
      "|permanent_name|display_name|city|state|country_code|member_since|occupation|loan_because|loan_purchase_num|invited_by|num_invited|\n",
      "+--------------+------------+----+-----+------------+------------+----------+------------+-----------------+----------+-----------+\n",
      "|      qian3013|        Qian|null| null|        null|  1461300457|      null|        null|              1.0|      null|          0|\n",
      "|     reena6733|       Reena|null| null|        null|  1461300634|      null|        null|              9.0|      null|          0|\n",
      "|       mai5982|         Mai|null| null|        null|  1461300853|      null|        null|             null|      null|          0|\n",
      "|andrew86079135|      Andrew|null| null|        null|  1461301091|      null|        null|              5.0| Peter Tan|          0|\n",
      "|    nguyen6962|      Nguyen|null| null|        null|  1461301154|      null|        null|             null|      null|          0|\n",
      "+--------------+------------+----+-----+------------+------------+----------+------------+-----------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lenders_df.printSchema()\n",
    "lenders_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- loan_name: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- description_translated: string (nullable = true)\n",
      " |-- funded_amount: string (nullable = true)\n",
      " |-- loan_amount: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- activity_name: string (nullable = true)\n",
      " |-- sector_name: string (nullable = true)\n",
      " |-- loan_use: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- town_name: string (nullable = true)\n",
      " |-- currency_policy: string (nullable = true)\n",
      " |-- currency_exchange_coverage_rate: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- partner_id: string (nullable = true)\n",
      " |-- posted_time: string (nullable = true)\n",
      " |-- planned_expiration_time: string (nullable = true)\n",
      " |-- disburse_time: string (nullable = true)\n",
      " |-- raised_time: string (nullable = true)\n",
      " |-- lender_term: string (nullable = true)\n",
      " |-- num_lenders_total: string (nullable = true)\n",
      " |-- num_journal_entries: string (nullable = true)\n",
      " |-- num_bulk_entries: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- borrower_genders: string (nullable = true)\n",
      " |-- borrower_pictured: string (nullable = true)\n",
      " |-- repayment_interval: string (nullable = true)\n",
      " |-- distribution_model: string (nullable = true)\n",
      "\n",
      "+-------+--------------+-----------------+--------------------+----------------------+--------------------+-----------+--------------------+--------------------+-----------+--------------------+------------+------------+--------------------+--------------------+-------------------------------+----------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+-----------------+------------------+------------------+\n",
      "|loan_id|     loan_name|original_language|         description|description_translated|       funded_amount|loan_amount|              status|       activity_name|sector_name|            loan_use|country_code|country_name|           town_name|     currency_policy|currency_exchange_coverage_rate|  currency|          partner_id|         posted_time|planned_expiration_time|       disburse_time|         raised_time|         lender_term|   num_lenders_total| num_journal_entries|    num_bulk_entries|                tags|borrower_genders|borrower_pictured|repayment_interval|distribution_model|\n",
      "+-------+--------------+-----------------+--------------------+----------------------+--------------------+-----------+--------------------+--------------------+-----------+--------------------+------------+------------+--------------------+--------------------+-------------------------------+----------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+-----------------+------------------+------------------+\n",
      "| 657307|          Aivy|          English|Aivy, 21 years of...|                  null|               125.0|      125.0|              funded|       General Store|     Retail| to buy additiona...|          PH| Philippines|Ozamiz - Ozamiz City|              shared|                            0.1|       PHP|               126.0|2014-01-15 02:23:...|   2014-02-14 03:30:...|2013-12-22 08:00:...|2014-01-15 04:48:...|                 7.0|                   3|                   2|                   1|                null|          female|             true|         irregular|     field_partner|\n",
      "| 657259|Idalia Marizza|          Spanish|Do√±a Idalia, esta...|  Idalia, 57, is ma...|               400.0|      400.0|              funded|       Used Clothing|   Clothing|To buy American c...|          HN|    Honduras|   La Lopez, Choloma|              shared|                            0.1|       HNL|               201.0|2014-01-14 20:23:...|   2014-03-26 22:25:...|2013-12-20 08:00:...|2014-02-25 06:42:...|                 8.0|                  11|                   2|                   1|                null|          female|             true|           monthly|     field_partner|\n",
      "| 658010|         Aasia|          English|Aasia is a 45-yea...|                  null|               400.0|      400.0|              funded|       General Store|     Retail|to buy stock of r...|          PK|    Pakistan|           Lala Musa|              shared|                            0.1|       PKR|               245.0|2014-01-16 11:32:...|   2014-02-15 21:10:...|2014-01-09 08:00:...|2014-01-24 23:06:...|                14.0|                  16|                   2|                   1|#Woman Owned Biz,...|          female|             true|           monthly|     field_partner|\n",
      "| 659347|       Gulmira|          Russian|–ì—É–ª–º–∏—Ä–µ 36 –ª–µ—Ç, –∑...|  \"Gulmira is 36 ye...| as well as ferti...| ultimately| their living con...| she and her husb...|      625.0|               625.0|      funded|     Farming|         Agriculture|to buy cucumber a...|                             KG|Kyrgyzstan|Aravan village, O...|              shared|                    0.1|                 KGS|               171.0|2014-01-20 09:59:...|2014-02-21 03:10:...|2014-01-17 08:00:...|2014-01-22 05:29:...|                14.0|              21|                2|                 1|     user_favorite|\n",
      "| 656933|       Ricky\\t|          English|Ricky is a farmer...|                  null|               425.0|      425.0|              funded|             Farming|Agriculture| to buy organic f...|          PH| Philippines|Baleleng, Sto. Th...|              shared|                            0.1|       PHP|               123.0|2014-01-14 05:46:...|   2014-02-13 06:10:...|2013-12-17 08:00:...|2014-01-14 17:29:...|                 7.0|                  15|                   2|                   1|#Animals, #Eco-fr...|            male|             true|            bullet|     field_partner|\n",
      "+-------+--------------+-----------------+--------------------+----------------------+--------------------+-----------+--------------------+--------------------+-----------+--------------------+------------+------------+--------------------+--------------------+-------------------------------+----------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------+-----------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_df.printSchema()\n",
    "loans_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read, transform and count loan_lenders \n",
    "string enumeration to rows: split tuple strings to array, then explode the array to rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row count:  27459086\n",
      "ellapsed time:  70.239741525\n",
      "+-------+-----------------+\n",
      "|loan_id|           lender|\n",
      "+-------+-----------------+\n",
      "|1000103|     kirramalatte|\n",
      "|1000103|     mike48519820|\n",
      "|1000141|       rachel1813|\n",
      "|1000193|    gwendolen8929|\n",
      "|1000200|     ryan18955662|\n",
      "|1000272|      bradley5620|\n",
      "|1000293|      william4267|\n",
      "|1000306|    david13647704|\n",
      "|1000306|        julie2056|\n",
      "|1000383|100ofhumanity1199|\n",
      "|1000400|        libby6754|\n",
      "|1000744|         hendrikd|\n",
      "|1000865|         remi5960|\n",
      "|1001124|         rick7694|\n",
      "|1001155|         mary8909|\n",
      "|1001209|         fran9888|\n",
      "|1001274|      suzanne3391|\n",
      "|1001378|        linda3440|\n",
      "|  10014|          sno7221|\n",
      "|1001431|          cas5618|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# loans_lenders_df10 = spark.sql(\" SELECT * FROM loans_lenders LIMIT 10 \") \n",
    "\n",
    "lldf = spark.read.csv(\"../../kiva/loans_lenders.csv\", header=True) # .limit(20) \n",
    "# full: 339 MB file, 1.387.433 lines --> 27.459.086, 27 sec, 1.2GB (6.3GB max) memory\n",
    "# 100.000 heading line --> 2.060.259 output lines\n",
    "# 200.000 heading line --> 4.110.948 output lines, 1.3 GB mem max\n",
    "\n",
    "loans_lenders_df = lldf.select( \\\n",
    "      lldf.loan_id, explode(split(lldf.lenders, ', ?')).alias('lender') \\\n",
    ").distinct() \n",
    "\n",
    "loans_lenders_df.createOrReplaceTempView(\"loans_lenders\") \n",
    "\n",
    "print('row count: ', loans_lenders_df.count())\n",
    "print('ellapsed time: ', timeit.default_timer() - start)\n",
    "loans_lenders_df.show()\n",
    "\n",
    "#loans_lenders_df.coalesce(1).write.csv('kiva/pyspark-loans_lenders_df-20.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join, filter and sort loan and lender data\n",
    "get distinct joined lines with renamed columns, then write to an output file (for fully materialized results)\n",
    "- filtering on lenders.country_code: \n",
    "  - 'US': 25% of lenders\n",
    "  - 'CA': 3% of lenders --> 3.5 GB joined, 1.971.548 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ellapsed time:  0.15953717000002143\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# remove previous folder if exists: \n",
    "import shutil\n",
    "try: \n",
    "    shutil.rmtree('../../kiva/pyspark-result-joined.csv')\n",
    "except FileNotFoundError: \n",
    "    pass\n",
    "\n",
    "# join and filter using SQL: \n",
    "joined_df = spark.sql(\"\"\"\n",
    "select distinct \n",
    "  le.permanent_name as lender_permanent_name, le.display_name as lender_display_name, \n",
    "  le.city as lender_city, le.state as lender_state, le.country_code as lender_country_code, \n",
    "  le.member_since as lender_member_since, le.occupation as lender_occupation, \n",
    "  le.loan_because as lender_loan_because, le.loan_purchase_num as lender_loan_purchase_num, \n",
    "  le.invited_by as lender_invited_by, le.num_invited as lender_num_invited, \n",
    "  lo.loan_id, lo.loan_name, lo.original_language, lo.description, lo.description_translated, \n",
    "  lo.funded_amount, lo.loan_amount, lo.status, lo.activity_name, lo.sector_name, \n",
    "  lo.loan_use, lo.country_code, lo.country_name, lo.town_name, lo.currency_policy, \n",
    "  lo.currency_exchange_coverage_rate, lo.currency, lo.partner_id, lo.posted_time, \n",
    "  lo.planned_expiration_time, lo.disburse_time, lo.raised_time, lo.lender_term, \n",
    "  lo.num_lenders_total, lo.num_journal_entries, lo.num_bulk_entries, lo.tags, \n",
    "  lo.borrower_genders, lo.borrower_pictured, lo.repayment_interval, lo.distribution_model\n",
    "from   loans_lenders as ll\n",
    "         inner join loans lo ON lo.loan_id = ll.loan_id\n",
    "         inner join lenders le ON le.permanent_name = ll.lender\n",
    "where  le.country_code = 'CA'\n",
    "order by lender_permanent_name, loan_id\n",
    "\"\"\")\n",
    "\n",
    "# coalesce(1) is for writing into one file\n",
    "#joined_df.coalesce(1).write.csv('../../kiva/pyspark-result-joined.csv', header=True)\n",
    "\n",
    "joined_df.createOrReplaceTempView(\"joined\") \n",
    "\n",
    "print('ellapsed time: ', timeit.default_timer() - start)\n",
    "#print('line count: ', joined_df.count() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group and sort joined data\n",
    "* group by on the joined ‚ÄòCA‚Äô table (3.5 GB): count distinct sector_name by lender, then sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* group by on the exploded loans_lenders table (6 GB): count distinct loan_id by lender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ellapsed time:  0.04001515400000244\n",
      "ellapsed time:  795.8832310860003\n",
      "+---------------------+-------+\n",
      "|lender_permanent_name|loan_ct|\n",
      "+---------------------+-------+\n",
      "|             aime8260|      1|\n",
      "|             alex1543|      1|\n",
      "|             alex1822|      1|\n",
      "|       alexandria3351|     62|\n",
      "|            alexx3309|      5|\n",
      "+---------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove previous results if exists: \n",
    "import shutil\n",
    "try: \n",
    "    shutil.rmtree('../../kiva/pyspark-result-groupby.csv')\n",
    "except FileNotFoundError: \n",
    "    pass\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "lender_loan_count_df = spark.sql(\"\"\"\n",
    "select lender_permanent_name, count(distinct loan_id) as loan_ct\n",
    "from   joined \n",
    "group by lender_permanent_name\n",
    "-- order by count(distinct loan_id) desc\n",
    "\"\"\")\n",
    "\n",
    "lender_loan_count_df.createOrReplaceTempView(\"lender_loan_count\")\n",
    "\n",
    "print('ellapsed time: ', timeit.default_timer() - start)\n",
    "\n",
    "lender_loan_count_df.coalesce(1).write.csv('../../kiva/pyspark-result-groupby.csv', header=True)\n",
    "print('ellapsed time: ', timeit.default_timer() - start)\n",
    "\n",
    "lender_loan_count_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- group by on the loans table (2.1 GB): sum funded_amount by sector_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
